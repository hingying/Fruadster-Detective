{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3049afff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24fa82a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = pd.read_csv('./simulated-data/fe_trans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85073b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans.TX_DATETIME = pd.to_datetime(trans.TX_DATETIME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03585c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3579099 entries, 0 to 3579098\n",
      "Data columns (total 32 columns):\n",
      " #   Column                                            Dtype         \n",
      "---  ------                                            -----         \n",
      " 0   TRANSACTION_ID                                    int64         \n",
      " 1   TX_DATETIME                                       datetime64[ns]\n",
      " 2   CUSTOMER_ID                                       int64         \n",
      " 3   TERMINAL_ID                                       int64         \n",
      " 4   TX_AMOUNT                                         float64       \n",
      " 5   TX_TIME_SECONDS                                   int64         \n",
      " 6   TX_TIME_DAYS                                      int64         \n",
      " 7   TX_FRAUD                                          int64         \n",
      " 8   TX_FRAUD_SCENARIO                                 int64         \n",
      " 9   TX_LAST_DATETIME                                  object        \n",
      " 10  TX_LAST_SECONDS                                   float64       \n",
      " 11  TX_LAST_HOURS                                     float64       \n",
      " 12  TX_LAST_DAYS                                      float64       \n",
      " 13  TX_TIME_HOUR_BIN_0                                int64         \n",
      " 14  TX_TIME_HOUR_BIN_1                                int64         \n",
      " 15  TX_TIME_HOUR_BIN_2                                int64         \n",
      " 16  TX_TIME_HOUR_BIN_3                                int64         \n",
      " 17  TX_TIME_HOUR_BIN_4                                int64         \n",
      " 18  TX_TIME_HOUR_BIN_5                                int64         \n",
      " 19  CUSTOMER_ID_AVG_AMOUNT_1DAY_WINDOW                float64       \n",
      " 20  CUSTOMER_ID_AVG_AMOUNT_7DAY_WINDOW                float64       \n",
      " 21  CUSTOMER_ID_AVG_AMOUNT_30DAY_WINDOW               float64       \n",
      " 22  CUSTOMER_ID_AVG_AMOUNT_2REC                       float64       \n",
      " 23  CUSTOMER_ID_AVG_AMOUNT_10REC                      float64       \n",
      " 24  TERMINAL_ID_RISK_2DAY_WINDOW                      float64       \n",
      " 25  TERMINAL_ID_RISK_7DAY_WINDOW                      float64       \n",
      " 26  SUM_TX_AMOUNT_CUSOMTER_ID_SAME_TERMINAL_SAME_DAY  float64       \n",
      " 27  nb_TX_CUSOMTER_ID_SAME_TERMINAL_SAME_DAY          int64         \n",
      " 28  ONE_DOLLAR                                        int64         \n",
      " 29  CUSTOMER_TERMINAL_DISTANCE                        float64       \n",
      " 30  AMOUNT_Z_SCORE                                    float64       \n",
      " 31  CUSTOMER_TERMINAL_DISTANCE_Z_SCORE                float64       \n",
      "dtypes: datetime64[ns](1), float64(15), int64(15), object(1)\n",
      "memory usage: 873.8+ MB\n"
     ]
    }
   ],
   "source": [
    "trans.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea9540f",
   "metadata": {},
   "source": [
    "**Supporting functions and constants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e00dba3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a baseline model. Use minimal feature set\n",
    "FEATURE_NUMERICAL = [\n",
    "    'TX_AMOUNT',\n",
    "#    'TX_TIME_SECONDS',\n",
    "#    'TX_TIME_DAYS',\n",
    "#    'TX_LAST_SECONDS',\n",
    "    'TX_LAST_HOURS',\n",
    "    'TX_LAST_DAYS',\n",
    "    'CUSTOMER_ID_AVG_AMOUNT_1DAY_WINDOW',    \n",
    "    'CUSTOMER_ID_AVG_AMOUNT_7DAY_WINDOW',\n",
    "    'CUSTOMER_ID_AVG_AMOUNT_30DAY_WINDOW',\n",
    "    'CUSTOMER_ID_AVG_AMOUNT_2REC',\n",
    "    'CUSTOMER_ID_AVG_AMOUNT_10REC',\n",
    "    'TERMINAL_ID_RISK_2DAY_WINDOW',\n",
    "    'TERMINAL_ID_RISK_7DAY_WINDOW',\n",
    "    'SUM_TX_AMOUNT_CUSOMTER_ID_SAME_TERMINAL_SAME_DAY',\n",
    "    'nb_TX_CUSOMTER_ID_SAME_TERMINAL_SAME_DAY',\n",
    "#    'CUSTOMER_TERMINAL_DISTANCE',\n",
    "    'AMOUNT_Z_SCORE',\n",
    "    'CUSTOMER_TERMINAL_DISTANCE_Z_SCORE'\n",
    "]\n",
    "\n",
    "FEATURE_CATEGORICAL = [\n",
    "     'TX_TIME_HOUR_BIN_0',\n",
    "     'TX_TIME_HOUR_BIN_1',\n",
    "     'TX_TIME_HOUR_BIN_2',\n",
    "     'TX_TIME_HOUR_BIN_3',\n",
    "     'TX_TIME_HOUR_BIN_4',\n",
    "     'TX_TIME_HOUR_BIN_5',\n",
    "     'ONE_DOLLAR'\n",
    "]\n",
    "\n",
    "FEATURE_LIST = FEATURE_NUMERICAL + FEATURE_CATEGORICAL\n",
    "\n",
    "ANOMALY_DETECTOR_FEATURE_EXCLUSION_LIST = [  # these features may be too sensitive to anomaly detector\n",
    "#    'TX_LAST_HOURS',\n",
    "#    'CUSTOMER_ID_AVG_AMOUNT_1DAY_WINDOW',    \n",
    "#    'CUSTOMER_ID_AVG_AMOUNT_7DAY_WINDOW',\n",
    "#    'CUSTOMER_ID_AVG_AMOUNT_30DAY_WINDOW',\n",
    "#    'CUSTOMER_ID_AVG_AMOUNT_2REC',\n",
    "#    'CUSTOMER_ID_AVG_AMOUNT_10REC',\n",
    "#    'TERMINAL_ID_RISK_2DAY_WINDOW',\n",
    "#    'TERMINAL_ID_RISK_7DAY_WINDOW'\n",
    "]\n",
    "\n",
    "# Target\n",
    "TARGET = 'TX_FRAUD'\n",
    "\n",
    "# Extract data from transaction df \n",
    "# Returns data greater than the start date and smaller than the end date\n",
    "def get_dataset_with_date(df,start_date,end_date): \n",
    "    time_period = (df['TX_DATETIME']>=start_date) & (df['TX_DATETIME'] <= end_date)\n",
    "    return df.loc[time_period]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# split and apply scaling to transaction data frame\n",
    "def train_test_split_and_scale(trans_df, train_date_range, test_date_range, scaler = None, genuine_only = False):   \n",
    "    ss = scaler\n",
    "\n",
    "    # Train data\n",
    "    train_df = get_dataset_with_date(trans_df, *train_date_range)\n",
    "    \n",
    "    if genuine_only == True:\n",
    "        train_df = train_df[train_df.TX_FRAUD == 0]\n",
    "\n",
    "    train_df_num = train_df[FEATURE_NUMERICAL]\n",
    "    train_df_cat = train_df[FEATURE_CATEGORICAL]\n",
    "    \n",
    "    if ss is None:\n",
    "        ss = StandardScaler()\n",
    "        ss.fit(train_df_num)\n",
    "        \n",
    "    train_fit_ss_X = ss.transform(train_df_num)\n",
    "\n",
    "    train_X_scaled = pd.DataFrame(train_fit_ss_X, columns = train_df_num.columns)\n",
    "    df_train_new = pd.concat([train_X_scaled, train_df_cat.reset_index(drop = True)],axis=1)\n",
    "    \n",
    "    y_train = train_df[TARGET]\n",
    "\n",
    "    # Test data\n",
    "    test_df = get_dataset_with_date(trans_df, *test_date_range)\n",
    "    test_df_num = test_df[FEATURE_NUMERICAL]\n",
    "    test_df_cat = test_df[FEATURE_CATEGORICAL]\n",
    "\n",
    "    test_fit_ss_X = ss.transform(test_df_num)  # should used the same, fitted scaler as above\n",
    "\n",
    "    test_X_scaled = pd.DataFrame(test_fit_ss_X, columns = test_df_num.columns)\n",
    "    df_test_new = pd.concat([test_X_scaled, test_df_cat.reset_index(drop = True)],axis=1)\n",
    "\n",
    "    y_test_df = test_df[['TRANSACTION_ID', 'TX_FRAUD_SCENARIO', TARGET]]\n",
    "    \n",
    "    return df_train_new, df_test_new, y_train, y_test_df, ss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d555a597",
   "metadata": {},
   "source": [
    "**Functions for metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4f4daa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "# Getting classes from a vector of fraud probabilities and a threshold\n",
    "def get_class_from_fraud_probability(fraud_probabilities, threshold=0.5):\n",
    "    \n",
    "    predicted_classes = [0 if fraud_probability<threshold else 1 \n",
    "                         for fraud_probability in fraud_probabilities]\n",
    "\n",
    "    return predicted_classes\n",
    "\n",
    "\n",
    "def threshold_based_metrics(fraud_probabilities, true_label, thresholds_list):\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    l = list(set(thresholds_list))\n",
    "    l.sort(reverse = True)\n",
    "    \n",
    "    for threshold in l:\n",
    "    \n",
    "        predicted_classes = get_class_from_fraud_probability(fraud_probabilities, threshold=threshold)\n",
    "    \n",
    "        (TN, FP, FN, TP) = metrics.confusion_matrix(true_label, predicted_classes).ravel()\n",
    "    \n",
    "        MME = (FP+FN)/(TN+FP+FN+TP)\n",
    "        \n",
    "        accuracy = 1 - MME\n",
    "    \n",
    "        TPR = TP/(TP+FN)\n",
    "        TNR = TN/(TN+FP)\n",
    "    \n",
    "        FPR = FP/(TN+FP)\n",
    "        FNR = FN/(TP+FN)\n",
    "        \n",
    "        BER = 1/2*(FPR+FNR)\n",
    "        \n",
    "        Gmean = np.sqrt(TPR*TNR)\n",
    "    \n",
    "        precision = 0\n",
    "        FDR = 0\n",
    "        F1_score=0\n",
    "        \n",
    "        if TP+FP>0:\n",
    "            precision = TP/(TP+FP)\n",
    "            FDR=FP/(TP+FP)\n",
    "        \n",
    "        NPV = 0\n",
    "        FOR = 0\n",
    "        \n",
    "        if TN+FN>0:\n",
    "            NPV = TN/(TN+FN)\n",
    "            FOR = FN/(TN+FN)\n",
    "            \n",
    "        \n",
    "        if precision+TPR>0:\n",
    "            F1_score = 2*(precision*TPR)/(precision+TPR)\n",
    "    \n",
    "        results.append([threshold, accuracy, MME, TPR, TNR, FPR, FNR, BER, Gmean, precision, NPV, FDR, FOR, F1_score])\n",
    "        \n",
    "    results_df = pd.DataFrame(results,columns=['Threshold', 'Accuracy', 'MME', 'TPR', 'TNR', 'FPR', 'FNR', 'BER', 'G-mean', 'Precision', 'NPV', 'FDR', 'FOR', 'F1 Score'])\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "\n",
    "def print_classification_report(y_test, fraud_probabilities, threshold):\n",
    "    \n",
    "    y_predict = [ 1 if p >= threshold else 0 for p in fraud_probabilities ]\n",
    "    \n",
    "    print(classification_report(y_test, y_predict))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_predict).ravel()\n",
    "    #print(tn, fp, fn, tp)\n",
    "    print([tp,fp])\n",
    "    print([fn,tn])\n",
    "\n",
    "\n",
    "def calculate_precision_recall(y_test, fraud_probabilities, threshold = 0.5):\n",
    "    \n",
    "    y_predict = [ 1 if p >= threshold else 0 for p in fraud_probabilities ]\n",
    "    \n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, y_predict).ravel()\n",
    "    print([tp,fp])\n",
    "    print([fn,tn])\n",
    "\n",
    "    precision = tp / (tp + fp) \n",
    "    recall = tp / (tp + fn)\n",
    "    return precision, recall\n",
    "    \n",
    "\n",
    "def plot_roc_curve(y_test, y_predict_probas):\n",
    "    \n",
    "    def get_template_roc_curve(ax, title,fs,random=True):\n",
    "\n",
    "        ax.set_title(title, fontsize=fs)\n",
    "        ax.set_xlim([-0.01, 1.01])\n",
    "        ax.set_ylim([-0.01, 1.01])\n",
    "\n",
    "        ax.set_xlabel('False Positive Rate', fontsize=fs)\n",
    "        ax.set_ylabel('True Positive Rate', fontsize=fs)\n",
    "\n",
    "        if random:\n",
    "            ax.plot([0, 1], [0, 1],'r--',label=\"AUC ROC Random = 0.5\")\n",
    "\n",
    "    FPR_list, TPR_list, threshold = metrics.roc_curve(y_test, y_predict_probas, drop_intermediate=False)\n",
    "\n",
    "    ROC_AUC = metrics.auc(FPR_list, TPR_list)    \n",
    "\n",
    "    roc_curve, ax = plt.subplots(figsize=(10,5))\n",
    "    get_template_roc_curve(ax, \"Receiver Operating Characteristic (ROC) Curve\",fs=15)\n",
    "    ax.plot(FPR_list, TPR_list, 'b', color='blue', label = 'AUC ROC Classifier = {0:0.3f}'.format(ROC_AUC))\n",
    "    ax.legend(loc = 'lower right')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_precisionrecall_curve(y_test, y_predict_probas, recalls, precisions):\n",
    "\n",
    "    def compute_AP(precision, recall):\n",
    "\n",
    "        AP = 0\n",
    "\n",
    "        n_thresholds = len(precision)\n",
    "\n",
    "        for i in range(1, n_thresholds):\n",
    "\n",
    "            if recall[i]-recall[i-1]>=0:\n",
    "\n",
    "                AP = AP+(recall[i]-recall[i-1])*precision[i]\n",
    "\n",
    "        return AP\n",
    "\n",
    "    def get_template_pr_curve(ax, title,fs, baseline=0.5):\n",
    "        ax.set_title(title, fontsize=fs)\n",
    "        ax.set_xlim([-0.01, 1.01])\n",
    "        ax.set_ylim([-0.01, 1.01])\n",
    "\n",
    "        ax.set_xlabel('Recall (True Positive Rate)', fontsize=fs)\n",
    "        ax.set_ylabel('Precision', fontsize=fs)\n",
    "\n",
    "        ax.plot([0, 1], [baseline, baseline],'r--',label='AP Random = {0:0.3f}'.format(baseline))\n",
    "\n",
    "    true_labels = prediction_df.TX_FRAUD\n",
    "    fraud_probabilities = prediction_df.FRAUD_PROBABILITY\n",
    "\n",
    "    pr_curve, ax = plt.subplots(figsize=(5,5))\n",
    "    get_template_pr_curve(ax, \"Precision Recall (PR) Curve\",fs=15,baseline=sum(true_labels)/len(true_labels))\n",
    "    AP2 = metrics.average_precision_score(true_labels, fraud_probabilities)\n",
    "    AP = compute_AP(precisions, recalls)\n",
    "    ax.step(recalls, precisions, 'b', color='blue', label = 'AP Classifier = {0:0.3f}'.format(AP))\n",
    "    ax.legend(loc = 'lower right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8374082c",
   "metadata": {},
   "source": [
    "**Create model for training**\n",
    "\n",
    "**(Replace this section with your classifier)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffde4858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "def create_classifier(hyper_params):\n",
    "    logmodel = XGBClassifier(**hyper_params)\n",
    "    return logmodel\n",
    "\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "def create_anomaly_detector(hyper_params):\n",
    "    model = OneClassSVM(**hyper_params)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e303f52",
   "metadata": {},
   "source": [
    "**Train model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e29fb2a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================================\n",
      "Dual model training round 1 of 1\n",
      "==============================================\n",
      "\n",
      "Train and evaluate fraud detector...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DS\\Applications\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:46:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "---- Classifier columns - train ----\n",
      "TX_AMOUNT                                           float64\n",
      "TX_LAST_HOURS                                       float64\n",
      "TX_LAST_DAYS                                        float64\n",
      "CUSTOMER_ID_AVG_AMOUNT_1DAY_WINDOW                  float64\n",
      "CUSTOMER_ID_AVG_AMOUNT_7DAY_WINDOW                  float64\n",
      "CUSTOMER_ID_AVG_AMOUNT_30DAY_WINDOW                 float64\n",
      "CUSTOMER_ID_AVG_AMOUNT_2REC                         float64\n",
      "CUSTOMER_ID_AVG_AMOUNT_10REC                        float64\n",
      "TERMINAL_ID_RISK_2DAY_WINDOW                        float64\n",
      "TERMINAL_ID_RISK_7DAY_WINDOW                        float64\n",
      "SUM_TX_AMOUNT_CUSOMTER_ID_SAME_TERMINAL_SAME_DAY    float64\n",
      "nb_TX_CUSOMTER_ID_SAME_TERMINAL_SAME_DAY            float64\n",
      "AMOUNT_Z_SCORE                                      float64\n",
      "CUSTOMER_TERMINAL_DISTANCE_Z_SCORE                  float64\n",
      "TX_TIME_HOUR_BIN_0                                    int64\n",
      "TX_TIME_HOUR_BIN_1                                    int64\n",
      "TX_TIME_HOUR_BIN_2                                    int64\n",
      "TX_TIME_HOUR_BIN_3                                    int64\n",
      "TX_TIME_HOUR_BIN_4                                    int64\n",
      "TX_TIME_HOUR_BIN_5                                    int64\n",
      "ONE_DOLLAR                                            int64\n",
      "dtype: object\n",
      "--- Classifier columns - test ----\n",
      "TX_AMOUNT                                           float64\n",
      "TX_LAST_HOURS                                       float64\n",
      "TX_LAST_DAYS                                        float64\n",
      "CUSTOMER_ID_AVG_AMOUNT_1DAY_WINDOW                  float64\n",
      "CUSTOMER_ID_AVG_AMOUNT_7DAY_WINDOW                  float64\n",
      "CUSTOMER_ID_AVG_AMOUNT_30DAY_WINDOW                 float64\n",
      "CUSTOMER_ID_AVG_AMOUNT_2REC                         float64\n",
      "CUSTOMER_ID_AVG_AMOUNT_10REC                        float64\n",
      "TERMINAL_ID_RISK_2DAY_WINDOW                        float64\n",
      "TERMINAL_ID_RISK_7DAY_WINDOW                        float64\n",
      "SUM_TX_AMOUNT_CUSOMTER_ID_SAME_TERMINAL_SAME_DAY    float64\n",
      "nb_TX_CUSOMTER_ID_SAME_TERMINAL_SAME_DAY            float64\n",
      "AMOUNT_Z_SCORE                                      float64\n",
      "CUSTOMER_TERMINAL_DISTANCE_Z_SCORE                  float64\n",
      "TX_TIME_HOUR_BIN_0                                    int64\n",
      "TX_TIME_HOUR_BIN_1                                    int64\n",
      "TX_TIME_HOUR_BIN_2                                    int64\n",
      "TX_TIME_HOUR_BIN_3                                    int64\n",
      "TX_TIME_HOUR_BIN_4                                    int64\n",
      "TX_TIME_HOUR_BIN_5                                    int64\n",
      "ONE_DOLLAR                                            int64\n",
      "dtype: object\n",
      "-----------------------------------------\n",
      "Train and evaluate anomaly detector...\n",
      "---- Anomaly Detector columns - train ----\n",
      "TX_AMOUNT                                           float64\n",
      "TX_LAST_HOURS                                       float64\n",
      "TX_LAST_DAYS                                        float64\n",
      "CUSTOMER_ID_AVG_AMOUNT_1DAY_WINDOW                  float64\n",
      "CUSTOMER_ID_AVG_AMOUNT_7DAY_WINDOW                  float64\n",
      "CUSTOMER_ID_AVG_AMOUNT_30DAY_WINDOW                 float64\n",
      "CUSTOMER_ID_AVG_AMOUNT_2REC                         float64\n",
      "CUSTOMER_ID_AVG_AMOUNT_10REC                        float64\n",
      "TERMINAL_ID_RISK_2DAY_WINDOW                        float64\n",
      "TERMINAL_ID_RISK_7DAY_WINDOW                        float64\n",
      "SUM_TX_AMOUNT_CUSOMTER_ID_SAME_TERMINAL_SAME_DAY    float64\n",
      "nb_TX_CUSOMTER_ID_SAME_TERMINAL_SAME_DAY            float64\n",
      "AMOUNT_Z_SCORE                                      float64\n",
      "CUSTOMER_TERMINAL_DISTANCE_Z_SCORE                  float64\n",
      "TX_TIME_HOUR_BIN_0                                    int64\n",
      "TX_TIME_HOUR_BIN_1                                    int64\n",
      "TX_TIME_HOUR_BIN_2                                    int64\n",
      "TX_TIME_HOUR_BIN_3                                    int64\n",
      "TX_TIME_HOUR_BIN_4                                    int64\n",
      "TX_TIME_HOUR_BIN_5                                    int64\n",
      "ONE_DOLLAR                                            int64\n",
      "dtype: object\n",
      "---- Anomaly Detector columns - test ----\n",
      "TX_AMOUNT                                           float64\n",
      "TX_LAST_HOURS                                       float64\n",
      "TX_LAST_DAYS                                        float64\n",
      "CUSTOMER_ID_AVG_AMOUNT_1DAY_WINDOW                  float64\n",
      "CUSTOMER_ID_AVG_AMOUNT_7DAY_WINDOW                  float64\n",
      "CUSTOMER_ID_AVG_AMOUNT_30DAY_WINDOW                 float64\n",
      "CUSTOMER_ID_AVG_AMOUNT_2REC                         float64\n",
      "CUSTOMER_ID_AVG_AMOUNT_10REC                        float64\n",
      "TERMINAL_ID_RISK_2DAY_WINDOW                        float64\n",
      "TERMINAL_ID_RISK_7DAY_WINDOW                        float64\n",
      "SUM_TX_AMOUNT_CUSOMTER_ID_SAME_TERMINAL_SAME_DAY    float64\n",
      "nb_TX_CUSOMTER_ID_SAME_TERMINAL_SAME_DAY            float64\n",
      "AMOUNT_Z_SCORE                                      float64\n",
      "CUSTOMER_TERMINAL_DISTANCE_Z_SCORE                  float64\n",
      "TX_TIME_HOUR_BIN_0                                    int64\n",
      "TX_TIME_HOUR_BIN_1                                    int64\n",
      "TX_TIME_HOUR_BIN_2                                    int64\n",
      "TX_TIME_HOUR_BIN_3                                    int64\n",
      "TX_TIME_HOUR_BIN_4                                    int64\n",
      "TX_TIME_HOUR_BIN_5                                    int64\n",
      "ONE_DOLLAR                                            int64\n",
      "dtype: object\n",
      "-----------------------------------------\n",
      "Thresholds and corresponding metrics. Should choose a threshold based on values of metrics.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Threshold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>MME</th>\n",
       "      <th>TPR</th>\n",
       "      <th>TNR</th>\n",
       "      <th>FPR</th>\n",
       "      <th>FNR</th>\n",
       "      <th>BER</th>\n",
       "      <th>G-mean</th>\n",
       "      <th>Precision</th>\n",
       "      <th>NPV</th>\n",
       "      <th>FDR</th>\n",
       "      <th>FOR</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.983236</td>\n",
       "      <td>0.016764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.983236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016764</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.994478</td>\n",
       "      <td>0.005522</td>\n",
       "      <td>0.683157</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.316843</td>\n",
       "      <td>0.158529</td>\n",
       "      <td>0.826444</td>\n",
       "      <td>0.981941</td>\n",
       "      <td>0.994626</td>\n",
       "      <td>0.018059</td>\n",
       "      <td>0.005374</td>\n",
       "      <td>0.805742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>0.727326</td>\n",
       "      <td>0.999712</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.272674</td>\n",
       "      <td>0.136481</td>\n",
       "      <td>0.852712</td>\n",
       "      <td>0.977315</td>\n",
       "      <td>0.995371</td>\n",
       "      <td>0.022685</td>\n",
       "      <td>0.004629</td>\n",
       "      <td>0.833990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.7</td>\n",
       "      <td>0.996173</td>\n",
       "      <td>0.003827</td>\n",
       "      <td>0.800353</td>\n",
       "      <td>0.999511</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.199647</td>\n",
       "      <td>0.100068</td>\n",
       "      <td>0.894406</td>\n",
       "      <td>0.965427</td>\n",
       "      <td>0.996606</td>\n",
       "      <td>0.034573</td>\n",
       "      <td>0.003394</td>\n",
       "      <td>0.875174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6</td>\n",
       "      <td>0.996301</td>\n",
       "      <td>0.003699</td>\n",
       "      <td>0.810758</td>\n",
       "      <td>0.999464</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.189242</td>\n",
       "      <td>0.094889</td>\n",
       "      <td>0.900180</td>\n",
       "      <td>0.962704</td>\n",
       "      <td>0.996782</td>\n",
       "      <td>0.037296</td>\n",
       "      <td>0.003218</td>\n",
       "      <td>0.880222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.996485</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.825285</td>\n",
       "      <td>0.999404</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.174715</td>\n",
       "      <td>0.087656</td>\n",
       "      <td>0.908181</td>\n",
       "      <td>0.959379</td>\n",
       "      <td>0.997028</td>\n",
       "      <td>0.040621</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>0.887294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0.996541</td>\n",
       "      <td>0.003459</td>\n",
       "      <td>0.846486</td>\n",
       "      <td>0.999100</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.153514</td>\n",
       "      <td>0.077207</td>\n",
       "      <td>0.919633</td>\n",
       "      <td>0.941279</td>\n",
       "      <td>0.997387</td>\n",
       "      <td>0.058721</td>\n",
       "      <td>0.002613</td>\n",
       "      <td>0.891370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.996512</td>\n",
       "      <td>0.003488</td>\n",
       "      <td>0.864154</td>\n",
       "      <td>0.998768</td>\n",
       "      <td>0.001232</td>\n",
       "      <td>0.135846</td>\n",
       "      <td>0.068539</td>\n",
       "      <td>0.929026</td>\n",
       "      <td>0.922851</td>\n",
       "      <td>0.997686</td>\n",
       "      <td>0.077149</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>0.892539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.995985</td>\n",
       "      <td>0.004015</td>\n",
       "      <td>0.873773</td>\n",
       "      <td>0.998069</td>\n",
       "      <td>0.001931</td>\n",
       "      <td>0.126227</td>\n",
       "      <td>0.064079</td>\n",
       "      <td>0.933855</td>\n",
       "      <td>0.885243</td>\n",
       "      <td>0.997848</td>\n",
       "      <td>0.114757</td>\n",
       "      <td>0.002152</td>\n",
       "      <td>0.879470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.995445</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>0.888496</td>\n",
       "      <td>0.997269</td>\n",
       "      <td>0.002731</td>\n",
       "      <td>0.111504</td>\n",
       "      <td>0.057117</td>\n",
       "      <td>0.941313</td>\n",
       "      <td>0.847248</td>\n",
       "      <td>0.998097</td>\n",
       "      <td>0.152752</td>\n",
       "      <td>0.001903</td>\n",
       "      <td>0.867382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016764</td>\n",
       "      <td>0.983236</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016764</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.983236</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Threshold  Accuracy       MME       TPR       TNR       FPR       FNR  \\\n",
       "0         1.0  0.983236  0.016764  0.000000  1.000000  0.000000  1.000000   \n",
       "1         0.9  0.994478  0.005522  0.683157  0.999786  0.000214  0.316843   \n",
       "2         0.8  0.995146  0.004854  0.727326  0.999712  0.000288  0.272674   \n",
       "3         0.7  0.996173  0.003827  0.800353  0.999511  0.000489  0.199647   \n",
       "4         0.6  0.996301  0.003699  0.810758  0.999464  0.000536  0.189242   \n",
       "5         0.5  0.996485  0.003515  0.825285  0.999404  0.000596  0.174715   \n",
       "6         0.4  0.996541  0.003459  0.846486  0.999100  0.000900  0.153514   \n",
       "7         0.3  0.996512  0.003488  0.864154  0.998768  0.001232  0.135846   \n",
       "8         0.2  0.995985  0.004015  0.873773  0.998069  0.001931  0.126227   \n",
       "9         0.1  0.995445  0.004555  0.888496  0.997269  0.002731  0.111504   \n",
       "10        0.0  0.016764  0.983236  1.000000  0.000000  1.000000  0.000000   \n",
       "\n",
       "         BER    G-mean  Precision       NPV       FDR       FOR  F1 Score  \n",
       "0   0.500000  0.000000   0.000000  0.983236  0.000000  0.016764  0.000000  \n",
       "1   0.158529  0.826444   0.981941  0.994626  0.018059  0.005374  0.805742  \n",
       "2   0.136481  0.852712   0.977315  0.995371  0.022685  0.004629  0.833990  \n",
       "3   0.100068  0.894406   0.965427  0.996606  0.034573  0.003394  0.875174  \n",
       "4   0.094889  0.900180   0.962704  0.996782  0.037296  0.003218  0.880222  \n",
       "5   0.087656  0.908181   0.959379  0.997028  0.040621  0.002972  0.887294  \n",
       "6   0.077207  0.919633   0.941279  0.997387  0.058721  0.002613  0.891370  \n",
       "7   0.068539  0.929026   0.922851  0.997686  0.077149  0.002314  0.892539  \n",
       "8   0.064079  0.933855   0.885243  0.997848  0.114757  0.002152  0.879470  \n",
       "9   0.057117  0.941313   0.847248  0.998097  0.152752  0.001903  0.867382  \n",
       "10  0.500000  0.000000   0.016764  0.000000  0.983236  0.000000  0.032974  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOR REFERENCE ONLY:\n",
      "Classifier threshold 0.7 \tArbitrate threshold 0.5 \tUnsettled default cl\n",
      "Classifier, threshold: 0.7\n",
      "[4077, 146]\n",
      "[1017, 298634]\n",
      "Precision 0.9654274212645039 \t\tRecall 0.8003533568904594\n",
      "Anomaly Detector\n",
      "[4538, 6018]\n",
      "[556, 292762]\n",
      "Precision 0.4298976885183782 \t\tRecall 0.8908519827247743\n",
      "Dual Model Detector\n",
      "[4312, 330]\n",
      "[782, 298450]\n",
      "Precision 0.9289099526066351 \t\tRecall 0.8464860620337652\n"
     ]
    }
   ],
   "source": [
    "CROSS_VALIDATION_INPUTS = [\n",
    "    {\n",
    "        'train_date_range' : ('2018-05-01 00:00:00', '2018-06-30 23:59:59'),   # mandatory\n",
    "        'test_date_range'  : ('2018-07-01 00:00:00', '2018-07-31 23:59:59'),   # mandatory\n",
    "        'classifier_hyper_params'     : {\n",
    "                                 'max_depth'      : 2,\n",
    "                                 'n_estimators'   : 100,\n",
    "                                 'learning_rate'  : 0.1,\n",
    "                                 'min_child_weight'   : 5,\n",
    "                                 'max_delta_step'       : 9,\n",
    "                                 'n_jobs'         : -1,\n",
    "                                 'random_state'   : 789\n",
    "                             },\n",
    "        'anomaly_detector_hyper_params'     : {\n",
    "                                 'kernel'         : 'rbf',\n",
    "                                 'nu'             : 0.02,\n",
    "#                                 'gamma'          : 0.007\n",
    "                             }\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def arb(ad_predict, cl_predict_proba, cl_threshold, arbitrate_threshold, default_model):\n",
    "    cl_predict = 1 if cl_predict_proba >= cl_threshold else 0\n",
    "\n",
    "    if ad_predict == cl_predict:\n",
    "        return (ad_predict, 'unanimous')\n",
    "\n",
    "    # arbitrate\n",
    "\n",
    "    cl_predict2 = None\n",
    "\n",
    "    if cl_predict == 0:\n",
    "        t = cl_threshold - (cl_threshold * arbitrate_threshold)\n",
    "        if cl_predict_proba >= t:\n",
    "            cl_predict2 = 1\n",
    "        else:\n",
    "            cl_predict2 = 0\n",
    "    elif cl_predict == 1:\n",
    "        t = (1 - cl_threshold) * arbitrate_threshold + cl_threshold\n",
    "        if cl_predict_proba >= t:\n",
    "            cl_predict2 = 1\n",
    "        else:\n",
    "            cl_predict2 = 0\n",
    "\n",
    "    if ad_predict == cl_predict2:\n",
    "        return (ad_predict, 'arbitrated')\n",
    "    elif default_model == 'cl':\n",
    "        return (cl_predict, 'unsettled')\n",
    "    elif default_model == 'ad':\n",
    "        return (ad_predict, 'unsettled')\n",
    "\n",
    "\n",
    "def arbitrate(predict_df, cl_threshold, arbitrate_threshold, default_model = 'cl'):\n",
    "\n",
    "    predict_probas = []\n",
    "    reasons = []\n",
    "    #predicts = []\n",
    "    \n",
    "    for i, r in predict_df.iterrows():\n",
    "        a = arb(r.AD_FRAUD_PROBABILITY, r.CL_FRAUD_PROBABILITY, cl_threshold, arbitrate_threshold, default_model)\n",
    "        predict_probas.append(int(a[0]))\n",
    "        reasons.append(a[1])\n",
    "        #predicts.append(a[2])\n",
    "\n",
    "    pred_df = predict_df.copy()\n",
    "    pred_df['DUAL_FRAUD_PROBABILITY'] = predict_probas\n",
    "    pred_df['DUAL_ARBITRATION'] = reasons\n",
    "    \n",
    "    return pred_df\n",
    "\n",
    "    \n",
    "def train_and_test_classifier(trans_df, cv_inputs):\n",
    "\n",
    "    # Classifier training\n",
    "    X_train, X_test, y_train, y_test_df, scaler = \\\n",
    "        train_test_split_and_scale(trans, cv_inputs['train_date_range'], cv_inputs['test_date_range'], scaler=None, genuine_only=False)\n",
    "    y_test = y_test_df[TARGET]\n",
    "    \n",
    "    cl_hyper_params = cv_inputs['classifier_hyper_params']\n",
    "    if cl_hyper_params is not None:\n",
    "        classifier = create_classifier(cl_hyper_params)\n",
    "    else:\n",
    "        classifier = create_classifier()\n",
    "\n",
    "    classifier.fit(X_train, y_train)\n",
    "\n",
    "    prediction_probas = classifier.predict_proba(X_test)[:, 1]\n",
    "    y_test_df['CL_FRAUD_PROBABILITY'] = prediction_probas\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, classifier, y_test_df, scaler\n",
    "\n",
    "\n",
    "def train_and_test_anomaly_detector(trans_df, cv_inputs):\n",
    "\n",
    "    # Anomaly detector training\n",
    "    X_train, X_test, y_train, y_test_df, scaler = \\\n",
    "        train_test_split_and_scale(trans, cv_inputs['train_date_range'], cv_inputs['test_date_range'], scaler=None, genuine_only=True)\n",
    "    y_test = y_test_df[TARGET]\n",
    "    \n",
    "    # remove sensitive features\n",
    "    X_train = X_train.drop(columns = ANOMALY_DETECTOR_FEATURE_EXCLUSION_LIST)\n",
    "    X_test = X_test.drop(columns = ANOMALY_DETECTOR_FEATURE_EXCLUSION_LIST)\n",
    "    \n",
    "    ad_hyper_params = cv_inputs['anomaly_detector_hyper_params']\n",
    "    if ad_hyper_params is not None:\n",
    "        anomaly_detector = create_anomaly_detector(ad_hyper_params)\n",
    "    else:\n",
    "        anomaly_detector = create_anomaly_detector()\n",
    "\n",
    "    anomaly_detector.fit(X_train)\n",
    "\n",
    "    prediction_probas = anomaly_detector.predict(X_test)\n",
    "    y_test_df['AD_FRAUD_PROBABILITY'] = [ 1 if p == -1 else 0 for p in prediction_probas ]\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test, anomaly_detector, y_test_df, scaler\n",
    "\n",
    "\n",
    "## Execution\n",
    "predicts_metrics = []\n",
    "\n",
    "for i, cv_inputs in enumerate(CROSS_VALIDATION_INPUTS):\n",
    "    print('\\n==============================================')\n",
    "    print('Dual model training round', i+1, 'of', len(CROSS_VALIDATION_INPUTS))\n",
    "    print('==============================================\\n')\n",
    "    \n",
    "    print('Train and evaluate fraud detector...')\n",
    "    X_train, X_test, y_train, y_test, classifier, cl_pred_df, cl_scaler = train_and_test_classifier(trans, cv_inputs)\n",
    "    print('---- Classifier columns - train ----')\n",
    "    print(X_train.dtypes)\n",
    "    print('--- Classifier columns - test ----')\n",
    "    print(X_test.dtypes)\n",
    "    print('-----------------------------------------')\n",
    "    \n",
    "    print('Train and evaluate anomaly detector...')\n",
    "    X_train, X_test, y_train, y_test, anomaly_detector, ad_pred_df, ad_scaler = train_and_test_anomaly_detector(trans, cv_inputs)\n",
    "    print('---- Anomaly Detector columns - train ----')\n",
    "    print(X_train.dtypes)\n",
    "    print('---- Anomaly Detector columns - test ----')\n",
    "    print(X_test.dtypes)\n",
    "    print('-----------------------------------------')\n",
    "    \n",
    "    prediction_df = cl_pred_df.copy()\n",
    "    prediction_df['AD_FRAUD_PROBABILITY'] = ad_pred_df['AD_FRAUD_PROBABILITY']\n",
    "    \n",
    "    # Display thresholds against all metrics, should choose a threshold base on metrics that need to be focus on\n",
    "    print('Thresholds and corresponding metrics. Should choose a threshold based on values of metrics.')\n",
    "    metrics_df = threshold_based_metrics(prediction_df.CL_FRAUD_PROBABILITY, prediction_df.TX_FRAUD, np.round(prediction_df.CL_FRAUD_PROBABILITY, decimals = 1))\n",
    "    display(metrics_df)\n",
    "        \n",
    "    \n",
    "    classifier_threshold = 0.7\n",
    "    arbitrate_threshold = 0.5\n",
    "    unsettled_default = 'cl'  # classifier\n",
    "    \n",
    "    print('FOR REFERENCE ONLY:')\n",
    "    print('Classifier threshold', classifier_threshold, '\\tArbitrate threshold', arbitrate_threshold, '\\tUnsettled default', unsettled_default)\n",
    "    \n",
    "    prediction_df = arbitrate(prediction_df, classifier_threshold, arbitrate_threshold, unsettled_default)\n",
    "    \n",
    "    print('Classifier, threshold:', classifier_threshold)\n",
    "    pre, re = calculate_precision_recall(y_test, prediction_df.CL_FRAUD_PROBABILITY, classifier_threshold)\n",
    "    print('Precision', pre, '\\t\\tRecall', re)\n",
    "    \n",
    "    print('Anomaly Detector')\n",
    "    pre, re = calculate_precision_recall(y_test, prediction_df.AD_FRAUD_PROBABILITY)\n",
    "    print('Precision', pre, '\\t\\tRecall', re)\n",
    "\n",
    "    print('Dual Model Detector')\n",
    "    pre, re = calculate_precision_recall(y_test, prediction_df.DUAL_FRAUD_PROBABILITY)\n",
    "    print('Precision', pre, '\\t\\tRecall', re)\n",
    "\n",
    "    predicts_metrics.append((prediction_df, metrics_df, classifier, anomaly_detector, cl_scaler, ad_scaler))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b7326f",
   "metadata": {},
   "source": [
    "**Save results to harddisk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48e12be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Round 1 results\n",
    "prediction_df, metrics_df, classifier, anomaly_detector, cl_scaler, ad_scaler = \\\n",
    "    predicts_metrics[0]\n",
    "\n",
    "import os\n",
    "\n",
    "if not os.path.exists('./dual_model_results'):\n",
    "    os.makedirs('./dual_model_results')\n",
    "\n",
    "prediction_df.to_csv('./dual_model_results/prediction.csv', index=False)\n",
    "metrics_df.to_csv('./dual_model_results/metrics.csv', index=False)\n",
    "\n",
    "import joblib\n",
    "joblib.dump(cl_scaler, './dual_model_results/classifier_scaler.bin', compress=True)\n",
    "joblib.dump(ad_scaler, './dual_model_results/anomaly_detector_scaler.bin', compress=True)\n",
    "\n",
    "import pickle\n",
    "pickle.dump(classifier, open('./dual_model_results/classifier_model.pkl', 'wb'))\n",
    "pickle.dump(anomaly_detector, open('./dual_model_results/anomaly_detector_model.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd1b90f2",
   "metadata": {},
   "source": [
    "**Load results from harddisk**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f27810d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Round 1 results\n",
    "prediction_df = pd.read_csv('./dual_model_results/prediction.csv')\n",
    "metrics_df = pd.read_csv('./dual_model_results/metrics.csv')\n",
    "\n",
    "import joblib\n",
    "cl_scaler = joblib.load('./dual_model_results/classifier_scaler.bin')\n",
    "ad_scaler = joblib.load('./dual_model_results/anomaly_detector_scaler.bin')\n",
    "\n",
    "import pickle\n",
    "classifier = pickle.load(open('./dual_model_results/classifier_model.pkl', 'rb'))\n",
    "anomaly_detector = pickle.load(open('./dual_model_results/anomaly_detector_model.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9c729c",
   "metadata": {},
   "source": [
    "**Analyze results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "771adb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_dual_model_result(input_prediction_df):\n",
    "\n",
    "    for classifier_threshold in [0.3, 0.4, 0.5, 0.6, 0.7]:\n",
    "        for arbitrate_threshold in [0.4, 0.5, 0.6]:\n",
    "            unsettled_default = 'cl'            \n",
    "            print('Classifier threshold', classifier_threshold, '\\tArbitrate threshold', arbitrate_threshold, '\\tUnsettled default', unsettled_default)\n",
    "\n",
    "            prediction_df = arbitrate(input_prediction_df, classifier_threshold, arbitrate_threshold, unsettled_default)\n",
    "\n",
    "            # --------------------------------------------------\n",
    "            # This part is same regardless of unsettled_default\n",
    "            print('* Classifier, threshold:', classifier_threshold)\n",
    "            pre, re = calculate_precision_recall(y_test, prediction_df.CL_FRAUD_PROBABILITY, classifier_threshold)\n",
    "            print('Precision', round(pre,2), '\\t\\tRecall', round(re,2))\n",
    "\n",
    "            print('* Anomaly Detector')\n",
    "            pre, re = calculate_precision_recall(y_test, prediction_df.AD_FRAUD_PROBABILITY)\n",
    "            print('Precision', round(pre,2), '\\t\\tRecall', round(re,2))\n",
    "            # --------------------------------------------------\n",
    "            \n",
    "            print('** Dual Model Detector - Using Classifier for unsettled cases')\n",
    "            pre, re = calculate_precision_recall(y_test, prediction_df.DUAL_FRAUD_PROBABILITY)\n",
    "            print('Precision', round(pre,2), '\\t\\tRecall', round(re,2))\n",
    "            \n",
    "            # --------------------------------------------------\n",
    "            # This part is same regardless of unsettled_default\n",
    "            reasons = prediction_df.DUAL_ARBITRATION.value_counts()\n",
    "\n",
    "            test_case_count = reasons.sum()\n",
    "            unanimous_pct = round(100 * reasons.unanimous / test_case_count, 2)\n",
    "            arbitrated_pct = round(100 * reasons.arbitrated / test_case_count, 2)\n",
    "            unsettled_pct = round(100 * reasons.unsettled / test_case_count, 2)\n",
    "\n",
    "            print( pd.DataFrame(prediction_df.DUAL_ARBITRATION.value_counts() ).transpose()[['unanimous','arbitrated','unsettled']] )            \n",
    "            print('Percentage           ', unanimous_pct, ' '*6, arbitrated_pct, ' '*5, unsettled_pct)\n",
    "            print()\n",
    "            # --------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb6e24fb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier threshold 0.3 \tArbitrate threshold 0.4 \tUnsettled default cl\n",
      "* Classifier, threshold: 0.3\n",
      "[4402, 368]\n",
      "[692, 298412]\n",
      "Precision 0.92 \t\tRecall 0.86\n",
      "* Anomaly Detector\n",
      "[4538, 6018]\n",
      "[556, 292762]\n",
      "Precision 0.43 \t\tRecall 0.89\n",
      "** Dual Model Detector - Using Classifier for unsettled cases\n",
      "[4444, 571]\n",
      "[650, 298209]\n",
      "Precision 0.89 \t\tRecall 0.87\n",
      "                  unanimous  arbitrated  unsettled\n",
      "DUAL_ARBITRATION     297874         317       5683\n",
      "Percentage            98.03        0.1       1.87\n",
      "\n",
      "Classifier threshold 0.3 \tArbitrate threshold 0.5 \tUnsettled default cl\n",
      "* Classifier, threshold: 0.3\n",
      "[4402, 368]\n",
      "[692, 298412]\n",
      "Precision 0.92 \t\tRecall 0.86\n",
      "* Anomaly Detector\n",
      "[4538, 6018]\n",
      "[556, 292762]\n",
      "Precision 0.43 \t\tRecall 0.89\n",
      "** Dual Model Detector - Using Classifier for unsettled cases\n",
      "[4463, 644]\n",
      "[631, 298136]\n",
      "Precision 0.87 \t\tRecall 0.88\n",
      "                  unanimous  arbitrated  unsettled\n",
      "DUAL_ARBITRATION     297874         427       5573\n",
      "Percentage            98.03        0.14       1.83\n",
      "\n",
      "Classifier threshold 0.3 \tArbitrate threshold 0.6 \tUnsettled default cl\n",
      "* Classifier, threshold: 0.3\n",
      "[4402, 368]\n",
      "[692, 298412]\n",
      "Precision 0.92 \t\tRecall 0.86\n",
      "* Anomaly Detector\n",
      "[4538, 6018]\n",
      "[556, 292762]\n",
      "Precision 0.43 \t\tRecall 0.89\n",
      "** Dual Model Detector - Using Classifier for unsettled cases\n",
      "[4470, 702]\n",
      "[624, 298078]\n",
      "Precision 0.86 \t\tRecall 0.88\n",
      "                  unanimous  arbitrated  unsettled\n",
      "DUAL_ARBITRATION     297874         512       5488\n",
      "Percentage            98.03        0.17       1.81\n",
      "\n",
      "Classifier threshold 0.4 \tArbitrate threshold 0.4 \tUnsettled default cl\n",
      "* Classifier, threshold: 0.4\n",
      "[4312, 269]\n",
      "[782, 298511]\n",
      "Precision 0.94 \t\tRecall 0.85\n",
      "* Anomaly Detector\n",
      "[4538, 6018]\n",
      "[556, 292762]\n",
      "Precision 0.43 \t\tRecall 0.89\n",
      "** Dual Model Detector - Using Classifier for unsettled cases\n",
      "[4401, 413]\n",
      "[693, 298367]\n",
      "Precision 0.91 \t\tRecall 0.86\n",
      "                  unanimous  arbitrated  unsettled\n",
      "DUAL_ARBITRATION     297711         287       5876\n",
      "Percentage            97.97        0.09       1.93\n",
      "\n",
      "Classifier threshold 0.4 \tArbitrate threshold 0.5 \tUnsettled default cl\n",
      "* Classifier, threshold: 0.4\n",
      "[4312, 269]\n",
      "[782, 298511]\n",
      "Precision 0.94 \t\tRecall 0.85\n",
      "* Anomaly Detector\n",
      "[4538, 6018]\n",
      "[556, 292762]\n",
      "Precision 0.43 \t\tRecall 0.89\n",
      "** Dual Model Detector - Using Classifier for unsettled cases\n",
      "[4408, 539]\n",
      "[686, 298241]\n",
      "Precision 0.89 \t\tRecall 0.87\n",
      "                  unanimous  arbitrated  unsettled\n",
      "DUAL_ARBITRATION     297711         440       5723\n",
      "Percentage            97.97        0.14       1.88\n",
      "\n",
      "Classifier threshold 0.4 \tArbitrate threshold 0.6 \tUnsettled default cl\n",
      "* Classifier, threshold: 0.4\n",
      "[4312, 269]\n",
      "[782, 298511]\n",
      "Precision 0.94 \t\tRecall 0.85\n",
      "* Anomaly Detector\n",
      "[4538, 6018]\n",
      "[556, 292762]\n",
      "Precision 0.43 \t\tRecall 0.89\n",
      "** Dual Model Detector - Using Classifier for unsettled cases\n",
      "[4420, 626]\n",
      "[674, 298154]\n",
      "Precision 0.88 \t\tRecall 0.87\n",
      "                  unanimous  arbitrated  unsettled\n",
      "DUAL_ARBITRATION     297711         623       5540\n",
      "Percentage            97.97        0.21       1.82\n",
      "\n",
      "Classifier threshold 0.5 \tArbitrate threshold 0.4 \tUnsettled default cl\n",
      "* Classifier, threshold: 0.5\n",
      "[4204, 178]\n",
      "[890, 298602]\n",
      "Precision 0.96 \t\tRecall 0.83\n",
      "* Anomaly Detector\n",
      "[4538, 6018]\n",
      "[556, 292762]\n",
      "Precision 0.43 \t\tRecall 0.89\n",
      "** Dual Model Detector - Using Classifier for unsettled cases\n",
      "[4363, 357]\n",
      "[731, 298423]\n",
      "Precision 0.92 \t\tRecall 0.86\n",
      "                  unanimous  arbitrated  unsettled\n",
      "DUAL_ARBITRATION     297538         386       5950\n",
      "Percentage            97.91        0.13       1.96\n",
      "\n",
      "Classifier threshold 0.5 \tArbitrate threshold 0.5 \tUnsettled default cl\n",
      "* Classifier, threshold: 0.5\n",
      "[4204, 178]\n",
      "[890, 298602]\n",
      "Precision 0.96 \t\tRecall 0.83\n",
      "* Anomaly Detector\n",
      "[4538, 6018]\n",
      "[556, 292762]\n",
      "Precision 0.43 \t\tRecall 0.89\n",
      "** Dual Model Detector - Using Classifier for unsettled cases\n",
      "[4357, 378]\n",
      "[737, 298402]\n",
      "Precision 0.92 \t\tRecall 0.86\n",
      "                  unanimous  arbitrated  unsettled\n",
      "DUAL_ARBITRATION     297538         475       5861\n",
      "Percentage            97.91        0.16       1.93\n",
      "\n",
      "Classifier threshold 0.5 \tArbitrate threshold 0.6 \tUnsettled default cl\n",
      "* Classifier, threshold: 0.5\n",
      "[4204, 178]\n",
      "[890, 298602]\n",
      "Precision 0.96 \t\tRecall 0.83\n",
      "* Anomaly Detector\n",
      "[4538, 6018]\n",
      "[556, 292762]\n",
      "Precision 0.43 \t\tRecall 0.89\n",
      "** Dual Model Detector - Using Classifier for unsettled cases\n",
      "[4368, 531]\n",
      "[726, 298249]\n",
      "Precision 0.89 \t\tRecall 0.86\n",
      "                  unanimous  arbitrated  unsettled\n",
      "DUAL_ARBITRATION     297538         661       5675\n",
      "Percentage            97.91        0.22       1.87\n",
      "\n",
      "Classifier threshold 0.6 \tArbitrate threshold 0.4 \tUnsettled default cl\n",
      "* Classifier, threshold: 0.6\n",
      "[4130, 160]\n",
      "[964, 298620]\n",
      "Precision 0.96 \t\tRecall 0.81\n",
      "* Anomaly Detector\n",
      "[4538, 6018]\n",
      "[556, 292762]\n",
      "Precision 0.43 \t\tRecall 0.89\n",
      "** Dual Model Detector - Using Classifier for unsettled cases\n",
      "[4320, 329]\n",
      "[774, 298451]\n",
      "Precision 0.93 \t\tRecall 0.85\n",
      "                  unanimous  arbitrated  unsettled\n",
      "DUAL_ARBITRATION     297470         467       5937\n",
      "Percentage            97.89        0.15       1.95\n",
      "\n",
      "Classifier threshold 0.6 \tArbitrate threshold 0.5 \tUnsettled default cl\n",
      "* Classifier, threshold: 0.6\n",
      "[4130, 160]\n",
      "[964, 298620]\n",
      "Precision 0.96 \t\tRecall 0.81\n",
      "* Anomaly Detector\n",
      "[4538, 6018]\n",
      "[556, 292762]\n",
      "Precision 0.43 \t\tRecall 0.89\n",
      "** Dual Model Detector - Using Classifier for unsettled cases\n",
      "[4323, 349]\n",
      "[771, 298431]\n",
      "Precision 0.93 \t\tRecall 0.85\n",
      "                  unanimous  arbitrated  unsettled\n",
      "DUAL_ARBITRATION     297470         502       5902\n",
      "Percentage            97.89        0.17       1.94\n",
      "\n",
      "Classifier threshold 0.6 \tArbitrate threshold 0.6 \tUnsettled default cl\n",
      "* Classifier, threshold: 0.6\n",
      "[4130, 160]\n",
      "[964, 298620]\n",
      "Precision 0.96 \t\tRecall 0.81\n",
      "* Anomaly Detector\n",
      "[4538, 6018]\n",
      "[556, 292762]\n",
      "Precision 0.43 \t\tRecall 0.89\n",
      "** Dual Model Detector - Using Classifier for unsettled cases\n",
      "[4350, 403]\n",
      "[744, 298377]\n",
      "Precision 0.92 \t\tRecall 0.85\n",
      "                  unanimous  arbitrated  unsettled\n",
      "DUAL_ARBITRATION     297470         589       5815\n",
      "Percentage            97.89        0.19       1.91\n",
      "\n",
      "Classifier threshold 0.7 \tArbitrate threshold 0.4 \tUnsettled default cl\n",
      "* Classifier, threshold: 0.7\n",
      "[4077, 146]\n",
      "[1017, 298634]\n",
      "Precision 0.97 \t\tRecall 0.8\n",
      "* Anomaly Detector\n",
      "[4538, 6018]\n",
      "[556, 292762]\n",
      "Precision 0.43 \t\tRecall 0.89\n",
      "** Dual Model Detector - Using Classifier for unsettled cases\n",
      "[4233, 250]\n",
      "[861, 298530]\n",
      "Precision 0.94 \t\tRecall 0.83\n",
      "                  unanimous  arbitrated  unsettled\n",
      "DUAL_ARBITRATION     297427         356       6091\n",
      "Percentage            97.88        0.12       2.0\n",
      "\n",
      "Classifier threshold 0.7 \tArbitrate threshold 0.5 \tUnsettled default cl\n",
      "* Classifier, threshold: 0.7\n",
      "[4077, 146]\n",
      "[1017, 298634]\n",
      "Precision 0.97 \t\tRecall 0.8\n",
      "* Anomaly Detector\n",
      "[4538, 6018]\n",
      "[556, 292762]\n",
      "Precision 0.43 \t\tRecall 0.89\n",
      "** Dual Model Detector - Using Classifier for unsettled cases\n",
      "[4312, 330]\n",
      "[782, 298450]\n",
      "Precision 0.93 \t\tRecall 0.85\n",
      "                  unanimous  arbitrated  unsettled\n",
      "DUAL_ARBITRATION     297427         521       5926\n",
      "Percentage            97.88        0.17       1.95\n",
      "\n",
      "Classifier threshold 0.7 \tArbitrate threshold 0.6 \tUnsettled default cl\n",
      "* Classifier, threshold: 0.7\n",
      "[4077, 146]\n",
      "[1017, 298634]\n",
      "Precision 0.97 \t\tRecall 0.8\n",
      "* Anomaly Detector\n",
      "[4538, 6018]\n",
      "[556, 292762]\n",
      "Precision 0.43 \t\tRecall 0.89\n",
      "** Dual Model Detector - Using Classifier for unsettled cases\n",
      "[4325, 354]\n",
      "[769, 298426]\n",
      "Precision 0.92 \t\tRecall 0.85\n",
      "                  unanimous  arbitrated  unsettled\n",
      "DUAL_ARBITRATION     297427         564       5883\n",
      "Percentage            97.88        0.19       1.94\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Round 1 results from above\n",
    "# prediction_df, metrics_df, classifier, anomaly_detector, cl_scaler, ad_scaler\n",
    "\n",
    "analyze_dual_model_result(prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60135a63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
